{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "809d7dce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from joblib import load\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.inspection import permutation_importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16042459",
   "metadata": {},
   "outputs": [],
   "source": [
    "CANDIDATE_PATHS = [\n",
    "    \"dataproject2025.csv\",\n",
    "    \"./data/dataproject2025.csv\",\n",
    "    \"/mnt/data/dataproject2025.csv\",\n",
    "]\n",
    "DATA_PATH = next((p for p in CANDIDATE_PATHS if os.path.exists(p)), CANDIDATE_PATHS[0])\n",
    "\n",
    "MODEL_PATH = \"outputs_step2/xgb_step2_model.joblib\"\n",
    "PRED_TEST_PATH = \"outputs_step2/xgb_step2_test_predictions.csv\"\n",
    "META_TXT_PATH = \"outputs_step2/Step_2 Meta.txt\"  # exact filename from your repo\n",
    "\n",
    "OUT_DIR = Path(\"outputs_step8\")\n",
    "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Permutation-importance params\n",
    "N_REPEATS = 10         # number of permutations per feature\n",
    "RANDOM_STATE = 42      # MUST match Step 2\n",
    "TEST_SIZE = 0.20       # MUST match Step 2 (80/20)\n",
    "TOPK_PLOT = 15\n",
    "\n",
    "# Step 2 parity flags\n",
    "USE_SAMPLE = False\n",
    "SAMPLE_N = 50_000\n",
    "EXCLUDE_SENSITIVE = False            # Meta shows False\n",
    "SENSITIVE_COLS = [\"Pct_afro_american\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d39e607a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_meta_baselines(meta_path):\n",
    "    roc_auc = None\n",
    "    pr_auc = None\n",
    "    if os.path.exists(meta_path):\n",
    "        with open(meta_path, \"r\") as f:\n",
    "            txt = f.read()\n",
    "        for line in txt.splitlines():\n",
    "            if \"ROC-AUC\" in line:\n",
    "                try:\n",
    "                    roc_auc = float(line.split(\"ROC-AUC:\")[1].split(\"|\")[0].strip())\n",
    "                except Exception:\n",
    "                    pass\n",
    "            if \"PR-AUC\" in line:\n",
    "                try:\n",
    "                    pr_auc = float(line.split(\"PR-AUC:\")[1].strip())\n",
    "                except Exception:\n",
    "                    pass\n",
    "    return roc_auc, pr_auc\n",
    "\n",
    "def load_model_safely(model_path):\n",
    "    if not os.path.exists(model_path):\n",
    "        raise FileNotFoundError(\n",
    "            f\"Model not found at '{model_path}'. \"\n",
    "            f\"Make sure outputs_step2/xgb_step2_model.joblib exists.\"\n",
    "        )\n",
    "    return load(model_path)\n",
    "\n",
    "def ensure_columns_order(X, feature_names):\n",
    "    missing = [c for c in feature_names if c not in X.columns]\n",
    "    if missing:\n",
    "        raise ValueError(f\"X_test is missing columns from trained model: {missing[:10]} ... total {len(missing)}\")\n",
    "    return X[feature_names]\n",
    "\n",
    "def find_prob_col(df):\n",
    "    # common candidates\n",
    "    for cand in [\"y_proba\",\"pred_proba\",\"prob_default\",\"yhat_proba\",\"pred\",\"proba\",\"p_default\"]:\n",
    "        if cand in df.columns:\n",
    "            return cand\n",
    "    # fallback: first float column in (0,1)\n",
    "    for c in df.columns:\n",
    "        s = df[c]\n",
    "        if np.issubdtype(s.dtype, np.number):\n",
    "            v = s.dropna()\n",
    "            if len(v) > 0:\n",
    "                mn, mx = v.min(), v.max()\n",
    "                if 0.0 <= mn and mx <= 1.0:\n",
    "                    return c\n",
    "    return None\n",
    "\n",
    "def plot_pi_bar(df_pi, out_path, topk=15, title=\"Permutation Importance (AUC drop)\"):\n",
    "    df_plot = df_pi.sort_values(\"mean_drop_auc\", ascending=False).head(topk)\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.bar(df_plot[\"feature\"], df_plot[\"mean_drop_auc\"], yerr=df_plot[\"std_drop_auc\"])\n",
    "    plt.xticks(rotation=60, ha=\"right\")\n",
    "    plt.ylabel(\"AUC drop (mean Â± std)\")\n",
    "    plt.title(title)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(out_path, dpi=200)\n",
    "    plt.close()\n",
    "\n",
    "# ==============================\n",
    "# Test-set loaders\n",
    "# ==============================\n",
    "def get_test_set_pathA():\n",
    "    \"\"\"Use pre-saved test set if available (recommended for consistency).\"\"\"\n",
    "    xt = Path(\"outputs_step2/X_test.csv\")\n",
    "    yt = Path(\"outputs_step2/y_test.csv\")\n",
    "    if xt.exists() and yt.exists():\n",
    "        X_test = pd.read_csv(xt)\n",
    "        y_test = pd.read_csv(yt).squeeze()\n",
    "        print(f\"[INFO] Loaded pre-saved test set: X_test={X_test.shape}, y_test={y_test.shape}\")\n",
    "        return X_test, y_test\n",
    "    return None, None\n",
    "\n",
    "def build_test_set_step2_logic(data_path):\n",
    "    \"\"\"Rebuild X_test, y_test strictly following Step 2 logic (your code snippet).\"\"\"\n",
    "    read_kwargs = dict(low_memory=False)\n",
    "    if not os.path.exists(data_path):\n",
    "        raise FileNotFoundError(\n",
    "            f\"Raw dataset not found: '{data_path}'. \"\n",
    "            f\"Place dataproject2025.csv in project root (or ./data/).\"\n",
    "        )\n",
    "    df = pd.read_csv(data_path, **read_kwargs)\n",
    "\n",
    "    if USE_SAMPLE and len(df) > SAMPLE_N:\n",
    "        df = df.sample(SAMPLE_N, random_state=RANDOM_STATE).reset_index(drop=True)\n",
    "\n",
    "    # Drop known leak / index columns if present\n",
    "    LEAKY_COLS = [\n",
    "        \"Predictions\", \"Predicted probabilities\", \"DP\", \"dp\",\n",
    "        \"Unnamed: 0\", \"id\", \"ID\", \"index\"\n",
    "    ]\n",
    "    present_leaky = [c for c in LEAKY_COLS if c in df.columns]\n",
    "    df = df.drop(columns=present_leaky, errors=\"ignore\")\n",
    "\n",
    "    # Target\n",
    "    assert \"target\" in df.columns, \"Expected 'target' column not found.\"\n",
    "    df[\"target\"] = df[\"target\"].astype(int)\n",
    "\n",
    "    # Optional: exclude sensitive columns for Step 2\n",
    "    if EXCLUDE_SENSITIVE:\n",
    "        drop_sens = [c for c in SENSITIVE_COLS if c in df.columns]\n",
    "        if drop_sens:\n",
    "            df = df.drop(columns=drop_sens)\n",
    "\n",
    "    # --- Parsers from Step 2 ---\n",
    "    def parse_emp_length(val):\n",
    "        if pd.isna(val):\n",
    "            return np.nan\n",
    "        s = str(val).strip().lower()\n",
    "        if s in {\"< 1 year\", \"less than 1 year\", \"<1 year\"}:\n",
    "            return 0.5\n",
    "        if s in {\"10+ years\", \"10+ yrs\", \"10+yr\"}:\n",
    "            return 10.0\n",
    "        for tok in s.replace(\"+\",\"\").split():\n",
    "            try:\n",
    "                return float(int(tok))\n",
    "            except:\n",
    "                continue\n",
    "        try:\n",
    "            return float(s)\n",
    "        except:\n",
    "            return np.nan\n",
    "\n",
    "    def parse_loan_duration(val):\n",
    "        if pd.isna(val):\n",
    "            return np.nan\n",
    "        if isinstance(val, (int, float)):\n",
    "            return float(val)\n",
    "        s = str(val).strip().lower().replace(\"months\",\"\").replace(\"month\",\"\").strip()\n",
    "        try:\n",
    "            return float(s)\n",
    "        except:\n",
    "            return np.nan\n",
    "\n",
    "    if \"emp_length\" in df.columns:\n",
    "        df[\"emp_length_parsed\"] = df[\"emp_length\"].apply(parse_emp_length)\n",
    "    if \"loan duration\" in df.columns:\n",
    "        df[\"loan_duration_parsed\"] = df[\"loan duration\"].apply(parse_loan_duration)\n",
    "\n",
    "    if \"issue_d\" in df.columns:\n",
    "        if df[\"issue_d\"].dtype == object:\n",
    "            d = pd.to_datetime(df[\"issue_d\"], errors=\"coerce\")\n",
    "            df[\"issue_d_ordinal\"] = d.map(lambda x: x.toordinal() if pd.notna(x) else np.nan)\n",
    "        else:\n",
    "            pass  # numeric already\n",
    "\n",
    "    # Identify feature columns (exclude high-card text)\n",
    "    target_col = \"target\"\n",
    "    all_features = [c for c in df.columns if c != target_col]\n",
    "    high_cardinality_text = {\"emp_title\"}\n",
    "    features = [c for c in all_features if c not in high_cardinality_text]\n",
    "\n",
    "    numeric_cols = [c for c in features if pd.api.types.is_numeric_dtype(df[c])]\n",
    "    categorical_cols = [c for c in features if c not in numeric_cols]\n",
    "\n",
    "    X = df[numeric_cols + categorical_cols].copy()\n",
    "    y = df[target_col].copy()\n",
    "\n",
    "    # float32 downcast for numeric cols (as Step 2)\n",
    "    for c in numeric_cols:\n",
    "        X[c] = pd.to_numeric(X[c], errors=\"coerce\").astype(\"float32\")\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=TEST_SIZE, stratify=y, random_state=RANDOM_STATE\n",
    "    )\n",
    "    print(f\"[INFO] Rebuilt test set via Step 2 logic: X_test={X_test.shape}, y_test={y_test.shape}\")\n",
    "    return X_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b05e5bf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    print(f\"[INFO] Using DATA_PATH = {DATA_PATH}\")\n",
    "    meta_roc, meta_pr = read_meta_baselines(META_TXT_PATH)\n",
    "    if meta_roc is not None or meta_pr is not None:\n",
    "        print(f\"[META] ROC-AUC={meta_roc} | PR-AUC={meta_pr}\")\n",
    "\n",
    "    # Load model\n",
    "    print(\"[INFO] Loading model ...\")\n",
    "    model = load_model_safely(MODEL_PATH)\n",
    "\n",
    "    # Try Path A (pre-saved test set) then Path B (rebuild)\n",
    "    X_test, y_test = get_test_set_pathA()\n",
    "    if X_test is None:\n",
    "        print(\"[INFO] Pre-saved test set not found. Rebuilding from raw CSV ...\")\n",
    "        X_test, y_test = build_test_set_step2_logic(DATA_PATH)\n",
    "\n",
    "    # Enforce training-time feature order if present\n",
    "    if hasattr(model, \"feature_names_in_\"):\n",
    "        X_test = ensure_columns_order(X_test, list(model.feature_names_in_))\n",
    "        print(f\"[INFO] Enforced feature order from model.feature_names_in_ ({X_test.shape[1]} cols).\")\n",
    "\n",
    "    # Baseline metrics\n",
    "    print(\"[INFO] Computing baseline metrics ...\")\n",
    "    if hasattr(model, \"predict_proba\"):\n",
    "        y_proba = model.predict_proba(X_test)[:, 1]\n",
    "    else:\n",
    "        # Some xgboost wrappers only expose predict with probabilities\n",
    "        y_pred = model.predict(X_test)\n",
    "        y_proba = y_pred if y_pred.ndim == 1 else y_pred[:, 1]\n",
    "\n",
    "    roc = roc_auc_score(y_test, y_proba)\n",
    "    pr = average_precision_score(y_test, y_proba)\n",
    "    print(f\"[BASELINE] ROC-AUC={roc:.6f} | PR-AUC={pr:.6f}\")\n",
    "\n",
    "    # Optional: compare with saved predictions (if exist)\n",
    "    if os.path.exists(PRED_TEST_PATH):\n",
    "        try:\n",
    "            df_pred = pd.read_csv(PRED_TEST_PATH)\n",
    "            prob_col = find_prob_col(df_pred)\n",
    "            if prob_col:\n",
    "                mae = float(np.mean(np.abs(df_pred[prob_col].values - y_proba)))\n",
    "                print(f\"[CHECK] MAE vs saved predictions ({prob_col}): {mae:.8e}\")\n",
    "            else:\n",
    "                print(\"[WARN] No obvious probability column found in saved predictions; skipping MAE check.\")\n",
    "        except Exception as e:\n",
    "            print(f\"[WARN] Could not compare to saved predictions: {e}\")\n",
    "\n",
    "    # Save baseline metrics\n",
    "    with open(OUT_DIR / \"baseline_metrics.json\", \"w\") as f:\n",
    "        json.dump({\"roc_auc\": float(roc), \"pr_auc\": float(pr), \"n_test\": int(len(y_test))}, f, indent=2)\n",
    "\n",
    "    # Wrapper to provide AUC as estimator.score for permutation_importance\n",
    "    class _AUCWrapper:\n",
    "        def __init__(self, base):\n",
    "            self.base = base\n",
    "        def predict_proba(self, X):\n",
    "            return self.base.predict_proba(X)\n",
    "        def predict(self, X):\n",
    "            if hasattr(self.base, \"predict_proba\"):\n",
    "                return self.base.predict_proba(X)[:, 1]\n",
    "            pred = self.base.predict(X)\n",
    "            return pred if pred.ndim == 1 else pred[:, 1]\n",
    "        def score(self, X, y):\n",
    "            p = self.predict(X)\n",
    "            return roc_auc_score(y, p)\n",
    "\n",
    "    print(\"[INFO] Running permutation importance (AUC-based) ...\")\n",
    "    r = permutation_importance(\n",
    "        estimator=model,\n",
    "        X=X_test,\n",
    "        y=y_test,\n",
    "        n_repeats=N_REPEATS,\n",
    "        random_state=RANDOM_STATE,\n",
    "        scoring=\"roc_auc\"  \n",
    "    )\n",
    "\n",
    "    features = list(X_test.columns)\n",
    "    df_pi = pd.DataFrame({\n",
    "        \"feature\": features,\n",
    "        \"mean_drop_auc\": r.importances_mean,\n",
    "        \"std_drop_auc\": r.importances_std\n",
    "    }).sort_values(\"mean_drop_auc\", ascending=False).reset_index(drop=True)\n",
    "    df_pi[\"rank\"] = np.arange(1, len(df_pi) + 1)\n",
    "\n",
    "    df_pi.to_csv(OUT_DIR / \"permutation_importance.csv\", index=False)\n",
    "    print(f\"[SAVE] {OUT_DIR/'permutation_importance.csv'}\")\n",
    "\n",
    "    plot_pi_bar(df_pi, OUT_DIR / \"pi_barplot_auc.png\", topk=TOPK_PLOT)\n",
    "    print(f\"[SAVE] {OUT_DIR/'pi_barplot_auc.png'}\")\n",
    "\n",
    "    # Persist test set for later steps (6â10) to ensure consistency\n",
    "    Path(\"outputs_step2\").mkdir(parents=True, exist_ok=True)\n",
    "    X_test.to_csv(\"outputs_step2/X_test.csv\", index=False)\n",
    "    y_test.to_csv(\"outputs_step2/y_test.csv\", index=False)\n",
    "    print(\"[SAVE] outputs_step2/X_test.csv & outputs_step2/y_test.csv\")\n",
    "\n",
    "    # Save run config\n",
    "    run_cfg = {\n",
    "        \"data_path\": DATA_PATH,\n",
    "        \"model_path\": MODEL_PATH,\n",
    "        \"meta_txt_path\": META_TXT_PATH,\n",
    "        \"n_repeats\": N_REPEATS,\n",
    "        \"random_state\": RANDOM_STATE,\n",
    "        \"test_size\": TEST_SIZE,\n",
    "        \"topk_plot\": TOPK_PLOT,\n",
    "        \"exclude_sensitive\": EXCLUDE_SENSITIVE,\n",
    "        \"sensitive_cols\": SENSITIVE_COLS,\n",
    "        \"used_presaved_test\": os.path.exists(\"outputs_step2/X_test.csv\")\n",
    "    }\n",
    "    with open(OUT_DIR / \"config.json\", \"w\") as f:\n",
    "        json.dump(run_cfg, f, indent=2)\n",
    "    print(f\"[SAVE] {OUT_DIR/'config.json'}\")\n",
    "\n",
    "    # Meta sanity check (optional but useful)\n",
    "    if meta_roc is not None:\n",
    "        delta = abs(roc - meta_roc)\n",
    "        if delta < 1e-4:\n",
    "            print(\"[CHECK] ROC-AUC matches Meta.txt â\")\n",
    "        else:\n",
    "            print(f\"[WARN] ROC-AUC differs from Meta.txt by {delta:.6f}. Re-check split/processing.\")\n",
    "    if meta_pr is not None:\n",
    "        delta = abs(pr - meta_pr)\n",
    "        if delta < 1e-4:\n",
    "            print(\"[CHECK] PR-AUC matches Meta.txt â\")\n",
    "        else:\n",
    "            print(f\"[WARN] PR-AUC differs from Meta.txt by {delta:.6f}. Re-check split/processing.\")\n",
    "\n",
    "    print(\"[DONE] Step 8 completed successfully â\")\n",
    "    print(f\"[OUTPUT DIR] {OUT_DIR.resolve()}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f77c8af3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
